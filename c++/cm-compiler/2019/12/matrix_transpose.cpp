/*
 * Copyright (c) 2017, Intel Corporation
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 */

#include <assert.h>
#include <iostream>

// The only CM runtime header file that you need is cm_rt.h.
// It includes all of the CM runtime.
#include "cm_rt.h"

// Includes cm_rt_helpers.h to convert the integer return code returned from
// the CM runtime to a meaningful string message.
#include "common/cm_rt_helpers.h"

// Includes isa_helpers.h to load the ISA file generated by the CM compiler.
#include "common/isa_helpers.h"

using namespace std;

void initMatrix(int *M, unsigned N)
{
    assert(N >= 8 && (((N - 1) & N) == 0) && "only power of 2 (>= 16) is supported");
    for (unsigned i = 0; i < N * N; ++i)
        M[i] = i;
}

void printMatrix(const char *msg, int *M, unsigned N)
{
    cerr << msg << "\n";
    if (N > 64) {
        cerr << "<<<maitrix of size " << N << " x " << N << ">>>\n";
        return;
    }

    for (unsigned i = 0; i < N; ++i) {
        for (unsigned j = 0; j < N; ++j) {
            cerr.width(4);
            cerr << M[i * N + j] << "  ";
        }
        cerr << "\n";
    }
}

bool checkResult(const int *M, unsigned N)
{
    for (unsigned i = 0; i < N; ++i) {
        for (unsigned j = 0; j < N; ++j) {
            unsigned t = M[j * N + i];
            if (t != i * N + j) {
                cerr << "Error at M(" << i << ", " << j << ") = " << t << "\n";
                return false;
            }
        }
    }
    return true;
}

bool runTest(unsigned N, unsigned block_size)
{
    int *M = (int *)CM_ALIGNED_MALLOC(N * N * sizeof(int), 0x1000);
    initMatrix(M, N);
    cerr << "\nTranspose square matrix of size " << N << "\n";
    // printMatrix("Initial matrix:", M, N);

    // Creates a CmDevice from scratch.
    // Param device: pointer to the CmDevice object.
    // Param version: CM API version supported by the runtime library.
    CmDevice *device = nullptr;
    unsigned version = 0;
    cm_result_check(::CreateCmDevice(device, version));

    // Load the virtual ISA file.
    std::string isa_code = cm::util::isa::loadFile("matrix_transpose_genx.isa");
    if (isa_code.empty()) {
        std::cerr << "Error: empty ISA binary.\n";
        std::exit(1);
    }

    // Creates a CmProgram object consisting of the kernels loaded from the code buffer.
    CmProgram *program = nullptr;
    cm_result_check(device->LoadProgram(const_cast<char *>(isa_code.data()),
        isa_code.size(), program));

    // Creates the kernel.
    CmKernel *kernel = nullptr;
    if (block_size == 16 && N >= 16)
        cm_result_check(device->CreateKernel(program, "transpose16", kernel));
    else if (block_size == 8)
        cm_result_check(device->CreateKernel(program, "transpose8", kernel));
    else
        assert("configuration not supported.");

    // Each CmKernel can be executed by multiple concurrent threads.
    // Each thread works on one or two blocks of size 8 x 8.
    int thread_width = N / block_size;
    int thread_height = N / block_size;

    // Creates a CmThreadSpace object.
    // There are two usage models for the thread space. One is to define the
    // dependency between threads to run in the GPU. The other is to define a
    // thread space where each thread can get a pair of coordinates during
    // kernel execution. For this example, we use the latter usage model.
    CmThreadSpace *thread_space = nullptr;
    cm_result_check(device->CreateThreadSpace(thread_width, thread_height, thread_space));

    // Gets the input/output surface index and set per kernel arguments.
    CmSurface2D *io_surface = nullptr;
    SurfaceIndex *surface_idx = nullptr;
    cm_result_check(device->CreateSurface2D(N, N, CM_SURFACE_FORMAT_R32F, io_surface));
    cm_result_check(io_surface->GetIndex(surface_idx));
    cm_result_check(kernel->SetKernelArg(0, sizeof(SurfaceIndex), surface_idx));

    // Creates a task queue and add the kernel.
    CmQueue *cmd_queue = nullptr;
    CmTask *task = nullptr;
    cm_result_check(device->CreateQueue(cmd_queue));
 
    unsigned long time_out = (-1);
    CmEvent *copy_event = CM_NO_EVENT;
    cm_result_check(cmd_queue->EnqueueCopyCPUToGPU(io_surface, (uint8_t *)M, copy_event));

    cm_result_check(device->CreateTask(task));
    cm_result_check(task->AddKernel(kernel));

    // Warmup.
    CmEvent *sync_event = nullptr;
    cm_result_check(cmd_queue->Enqueue(task, sync_event, thread_space));
    time_out = (-1);
    cm_result_check(sync_event->WaitForTaskFinished(time_out));

    // Start timer.
    double start = getTimeStamp();

    // Launches the task on the GPU.
    UINT64 kernel_time_in_ns = 0;
    unsigned num_iters = 10;

    for (int i = 0; i < num_iters; ++i) {
        UINT64 time_in_ns = 0;
        cm_result_check(cmd_queue->Enqueue(task, sync_event, thread_space));
        cm_result_check(sync_event->WaitForTaskFinished(time_out));
        cm_result_check(sync_event->GetExecutionTime(time_in_ns));
        kernel_time_in_ns += time_in_ns;
    }

    // End timer.
    double end = getTimeStamp();

    float total_time = (end - start) * 1000.0f / num_iters;
    float kernel_time = kernel_time_in_ns / 1000000.0f / num_iters;

    float bandwidth_total = 2.0f * 1000 * sizeof(int) * N * N / (1024 * 1024 * 1024) / total_time;
    float bandwidth_kernel = 2.0f * 1000 * sizeof(int) * N * N / (1024 * 1024 * 1024) / kernel_time;

    cerr << "GPU transposition time = " << total_time << " msec\n";
    cerr << "GPU transposition bandwidth = " << bandwidth_total << " GB/s\n";
    cerr << "GPU kernel time = " << kernel_time << " msec\n";
    cerr << "GPU kernel bandwidth = " << bandwidth_kernel << " GB/s\n";

    // Cleanup.
    time_out = (-1);
    copy_event = CM_NO_EVENT;
    cm_result_check(cmd_queue->EnqueueCopyGPUToCPU(io_surface, (uint8_t *)M, copy_event));
    cm_result_check(device->DestroyTask(task));
    cm_result_check(device->DestroyThreadSpace(thread_space));
    cm_result_check(::DestroyCmDevice(device));

    // printMatrix("\nTransposed matrix:", M, N);
    bool success = checkResult(M, N);
    CM_ALIGNED_FREE(M);
    return success;
}

int main(int argc, char *argv[])
{
    unsigned N = 1U << 5;
    if (argc >= 2) {
        unsigned exponent = atoi(argv[1]);
        N = max(N, 1U << exponent);
        N = min(N, 1U << 12);
    }

    bool success = true;
    success &= runTest(N, 8);
    success &= runTest(1U << 10, 8);
    success &= runTest(1U << 11, 8);
    success &= runTest(1U << 12, 8);
    success &= runTest(1U << 13, 8);
    success &= runTest(1U << 10, 16);
    success &= runTest(1U << 11, 16);
    success &= runTest(1U << 12, 16);
    success &= runTest(1U << 13, 16);

    cerr << (success ? "PASSED\n" : "FAILED\n");
    return !success;
}
